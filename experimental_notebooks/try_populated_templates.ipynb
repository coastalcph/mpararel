{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.path.dirname(\"/home/wsr217/mpararel/\")))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "from tqdm import tqdm\n",
    "from dataset.translate_templates import *\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "translator = TRANSLATOR_TO_OBJECT[Translator.GOOGLE]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "K_POPULATED_TEMPLATES = 10"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "templates_folder = '/home/wsr217/mpararel/data/pararel'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "tuples_folder = '/home/wsr217/mpararel/generated_datasets/mpararel_bing'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "for relation_filename in tqdm(os.listdir(templates_folder)):\n",
    "    templates = get_templates(os.path.join(templates_folder, relation_filename))\n",
    "    if relation_filename == \"P36.jsonl\":\n",
    "        break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 82%|████████▏ | 32/39 [00:00<00:00, 809.80it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "templates"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'pattern': 'The capital of [X] is [Y] .',\n",
       "  'lemma': 'capital',\n",
       "  'extended_lemma': 'capital-of',\n",
       "  'tense': 'present'},\n",
       " {'pattern': 'The capital city of [X] is [Y].',\n",
       "  'lemma': 'capital-city',\n",
       "  'extended_lemma': 'capital-city-of',\n",
       "  'tense': 'present'},\n",
       " {'pattern': '[Y] is the capital of [X].',\n",
       "  'lemma': 'capital',\n",
       "  'extended_lemma': 'capital-of',\n",
       "  'tense': 'present'},\n",
       " {'pattern': '[Y] is the capital city of [X].',\n",
       "  'lemma': 'capital-city',\n",
       "  'extended_lemma': 'capital-city-of',\n",
       "  'tense': 'present'},\n",
       " {'pattern': \"[X]'s capital, [Y].\",\n",
       "  'lemma': 'capital',\n",
       "  'extended_lemma': 'capital-of',\n",
       "  'tense': 'present'},\n",
       " {'pattern': \"[X]'s capital city, [Y].\",\n",
       "  'lemma': 'capital-city',\n",
       "  'extended_lemma': 'capital-city-of',\n",
       "  'tense': 'present'},\n",
       " {'pattern': \"[X]'s capital is [Y].\",\n",
       "  'lemma': 'capital',\n",
       "  'extended_lemma': 'capital-of',\n",
       "  'tense': 'present'},\n",
       " {'pattern': \"[X]'s capital city is [Y].\",\n",
       "  'lemma': 'capital-city',\n",
       "  'extended_lemma': 'capital-city-of',\n",
       "  'tense': 'present'},\n",
       " {'pattern': '[Y], the capital of [X].',\n",
       "  'lemma': 'capital',\n",
       "  'extended_lemma': 'capital-of',\n",
       "  'tense': 'present'},\n",
       " {'pattern': '[Y], the capital city of [X].',\n",
       "  'lemma': 'capital-city',\n",
       "  'extended_lemma': 'capital-city-of',\n",
       "  'tense': 'present'},\n",
       " {'pattern': '[Y], that is the capital of [X].',\n",
       "  'lemma': 'capital',\n",
       "  'extended_lemma': 'capital-of',\n",
       "  'tense': 'present'},\n",
       " {'pattern': '[Y], that is the capital city of [X].',\n",
       "  'lemma': 'capital-city',\n",
       "  'extended_lemma': 'capital-city-of',\n",
       "  'tense': 'present'},\n",
       " {'pattern': '[X], which has the capital [Y].',\n",
       "  'lemma': 'capital',\n",
       "  'extended_lemma': 'capital-of',\n",
       "  'tense': 'present'},\n",
       " {'pattern': '[X], which has the capital city [Y].',\n",
       "  'lemma': 'capital-city',\n",
       "  'extended_lemma': 'capital-city-of',\n",
       "  'tense': 'present'}]"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "def get_k_subject_object_tuples(filename, k_tuples):\n",
    "    tuples = {}\n",
    "    added = set()\n",
    "    with open(filename) as fp:\n",
    "        for i, line in enumerate(fp):\n",
    "            line_data = json.loads(line)\n",
    "            if (line_data[\"sub_label\"] not in added and\n",
    "                    line_data[\"obj_label\"] not in added):\n",
    "                tuples[line_data[\"lineid\"]] = (line_data[\"sub_label\"], line_data[\"obj_label\"])\n",
    "                added.add(line_data[\"sub_label\"])\n",
    "                added.add(line_data[\"obj_label\"])\n",
    "            if len(tuples) == k_tuples:\n",
    "                break\n",
    "    return tuples"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "def get_subject_object_tuples_from_lines(filename, lineas_to_add):\n",
    "    tuples = {}\n",
    "    with open(filename) as fp:\n",
    "        for i, line in enumerate(fp):\n",
    "            line_data = json.loads(line)\n",
    "            if line_data[\"lineid\"] in lineas_to_add:\n",
    "                tuples[line_data[\"lineid\"]] = (line_data[\"sub_label\"], line_data[\"obj_label\"])\n",
    "    return tuples"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "def get_populated_phrases(template, tuples):\n",
    "    populated_phrases = []\n",
    "    for obj, sub in tuples:\n",
    "        phrase = template.replace(\"[X]\", obj)\n",
    "        populated_phrases.append(phrase.replace(\"[Y]\", sub))\n",
    "    return populated_phrases"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "def longest_common_subsequence(string_list_1, string_list_2):\n",
    "    m = len(string_list_1)\n",
    "    n = len(string_list_2)\n",
    "    # L[i][j] contains the length of the LCS of X[0..i-1] and Y[0..j-1].\n",
    "    L = [[None]*(n + 1) for i in range(m + 1)]\n",
    "    sequence = [[None]*(n + 1) for i in range(m + 1)]\n",
    "    for i in range(m + 1):\n",
    "        for j in range(n + 1):\n",
    "            if i == 0 or j == 0:\n",
    "                L[i][j] = 0\n",
    "                sequence[i][j] = ''\n",
    "            elif string_list_1[i-1] == string_list_2[j-1]:\n",
    "                L[i][j] = L[i-1][j-1] + 1\n",
    "                sequence[i][j] = sequence[i-1][j-1] + ' ' + string_list_1[i-1]\n",
    "            else:\n",
    "                if L[i-1][j] > L[i][j-1]:\n",
    "                    L[i][j] = L[i-1][j]\n",
    "                    sequence[i][j] = sequence[i-1][j]\n",
    "                else:\n",
    "                    L[i][j] = L[i][j-1]\n",
    "                    sequence[i][j] = sequence[i][j-1]\n",
    "    return '' if not sequence[m][n] else sequence[m][n][1:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "def longest_common_subsequence(string_list_1, string_list_2):\n",
    "    print(\"searching lcs between:\",string_list_1, string_list_2)\n",
    "    m = len(string_list_1)\n",
    "    n = len(string_list_2)\n",
    "    # L[i][j] contains the length of the LCS of X[0..i-1] and Y[0..j-1].\n",
    "    L = [[None]*(n + 1) for i in range(m + 1)]\n",
    "    sequence = [[None]*(n + 1) for i in range(m + 1)]\n",
    "    for i in range(m + 1):\n",
    "        for j in range(n + 1):\n",
    "            if i == 0 or j == 0:\n",
    "                L[i][j] = 0\n",
    "                sequence[i][j] = []\n",
    "            elif string_list_1[i-1] == string_list_2[j-1]:\n",
    "                L[i][j] = L[i-1][j-1] + 1\n",
    "                sequence[i][j] = sequence[i-1][j-1].copy() + [(i-1, j-1)]\n",
    "                #print(\"{} and {} are the same\".format(i-1, j-1))\n",
    "                #print(\"sequence[i-1][j-1]:\", sequence[i-1][j-1])\n",
    "                #print(\"sequence[i][j]:\", sequence[i][j])\n",
    "            else:\n",
    "                if L[i-1][j] > L[i][j-1]:\n",
    "                    L[i][j] = L[i-1][j]\n",
    "                    sequence[i][j] = sequence[i-1][j]\n",
    "                else:\n",
    "                    L[i][j] = L[i][j-1]\n",
    "                    sequence[i][j] = sequence[i][j-1]\n",
    "    lcs = sequence[m][n]\n",
    "    if not lcs:\n",
    "        return None, None\n",
    "    str_sequence = []\n",
    "    skipped = []\n",
    "    for i_common in range(len(lcs)):\n",
    "        # Some words are skipped in both strings between the last common and the\n",
    "        # current common index.\n",
    "        last_common_index_1st_word = -1 if i_common == 0 else lcs[i_common-1][0]\n",
    "        last_common_index_2nd_word = -1 if i_common == 0 else lcs[i_common-1][1]\n",
    "        if (lcs[i_common][0] > last_common_index_1st_word + 1\n",
    "                and lcs[i_common][1] > last_common_index_2nd_word + 1):\n",
    "            str_sequence.append('[X/Y]')\n",
    "            skipped_str_1 = ' '.join(\n",
    "                string_list_1[last_common_index_1st_word + 1 : lcs[i_common][0]])\n",
    "            skipped_str_2 = ' '.join(\n",
    "                string_list_2[last_common_index_2nd_word + 1 : lcs[i_common][1]])\n",
    "            skipped.append((skipped_str_1, skipped_str_2))\n",
    "        str_sequence.append(string_list_1[lcs[i_common][0]])\n",
    "    if (len(string_list_1) > lcs[i_common][0] + 1 and\n",
    "            len(string_list_2) > lcs[i_common][1] + 1):\n",
    "        str_sequence.append('[X/Y]')\n",
    "        skipped_str_1 = ' '.join(string_list_1[lcs[i_common][0] + 1 :])\n",
    "        skipped_str_2 = ' '.join(string_list_2[lcs[i_common][1] + 1 :])\n",
    "        skipped.append((skipped_str_1, skipped_str_2))\n",
    "    return ' '.join(str_sequence), skipped"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "translated_phrases"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Αζερμπαϊτζάν, που έχει την πρωτεύουσα Μπακού.',\n",
       " 'Brody Raion, που έχει την πρωτεύουσα Brody.',\n",
       " 'Cook County, το οποίο έχει την πρωτεύουσα Σικάγο.',\n",
       " 'Fort Bend County, η οποία έχει την πρωτεύουσα της πόλης Richmond.',\n",
       " 'Cailuga County, η οποία έχει την πρωτεύουσα Auburn.',\n",
       " 'Πόλη Hawkesbury, που έχει την πρωτεύουσα του Windsor.',\n",
       " 'Grand Est, που έχει την πρωτεύουσα του Στρασβούργου.',\n",
       " 'Caddo Parish, η οποία έχει την πρωτεύουσα Shreveport.',\n",
       " 'Η Νεμπράσκα, η οποία έχει την πρωτεύουσα Lincoln.',\n",
       " 'Hampshire, η οποία έχει την πρωτεύουσα της πόλης Winchester.']"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "final_templates = get_templates_from_populated_translations(\n",
    "        translated_phrases, en_tuples.values(), translated_tuples.values())\n",
    "final_templates"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "searching lcs between: ['Το', 'κεφάλαιο', 'του', 'Αζερμπαϊτζάν', ',', 'το', 'Μπακού', '.'] ['Το', 'κεφάλαιο', 'του', 'Brody', 'Raion', ',', 'Brody', '.']\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'του', 'Αζερμπαϊτζάν', ',', 'το', 'Μπακού', '.'] ['Cook', \"County's\", 'Capital', ',', 'Σικάγο', '.']\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'του', 'Αζερμπαϊτζάν', ',', 'το', 'Μπακού', '.'] ['Το', 'κεφάλαιο', 'της', 'κομητείας', 'Fort', 'Bend', ',', 'Richmond', '.']\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'του', 'Αζερμπαϊτζάν', ',', 'το', 'Μπακού', '.'] ['Το', 'κεφάλαιο', 'της', 'Cayuga', 'County', ',', 'Auburn', '.']\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'του', 'Αζερμπαϊτζάν', ',', 'το', 'Μπακού', '.'] ['Πόλη', 'της', 'πρωτεύουσας', 'του', 'Hawkesbury', ',', 'Windsor', '.']\n",
      "Error in lcs, there aren't two '[X/Y]': [X/Y] του [X/Y] , [X/Y] .\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'του', 'Αζερμπαϊτζάν', ',', 'το', 'Μπακού', '.'] ['Κεφάλαιο', 'του', 'Grand', 'Est', ',', 'Στρασβούργο', '.']\n",
      "Error in lcs, there aren't two '[X/Y]': [X/Y] του [X/Y] , [X/Y] .\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'του', 'Αζερμπαϊτζάν', ',', 'το', 'Μπακού', '.'] ['Το', 'κεφάλαιο', 'του', 'Caddo', 'Parish', ',', 'το', 'Shreveport', '.']\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'του', 'Αζερμπαϊτζάν', ',', 'το', 'Μπακού', '.'] ['Το', 'κεφάλαιο', 'της', 'Νεμπράσκα', ',', 'το', 'Λίνκολν', '.']\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'του', 'Αζερμπαϊτζάν', ',', 'το', 'Μπακού', '.'] ['Το', 'κεφάλαιο', 'του', 'Hampshire', ',', 'το', 'Winchester', '.']\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'του', 'Brody', 'Raion', ',', 'Brody', '.'] ['Cook', \"County's\", 'Capital', ',', 'Σικάγο', '.']\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'του', 'Brody', 'Raion', ',', 'Brody', '.'] ['Το', 'κεφάλαιο', 'της', 'κομητείας', 'Fort', 'Bend', ',', 'Richmond', '.']\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'του', 'Brody', 'Raion', ',', 'Brody', '.'] ['Το', 'κεφάλαιο', 'της', 'Cayuga', 'County', ',', 'Auburn', '.']\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'του', 'Brody', 'Raion', ',', 'Brody', '.'] ['Πόλη', 'της', 'πρωτεύουσας', 'του', 'Hawkesbury', ',', 'Windsor', '.']\n",
      "Error in lcs, there aren't two '[X/Y]': [X/Y] του [X/Y] , [X/Y] .\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'του', 'Brody', 'Raion', ',', 'Brody', '.'] ['Κεφάλαιο', 'του', 'Grand', 'Est', ',', 'Στρασβούργο', '.']\n",
      "Error in lcs, there aren't two '[X/Y]': [X/Y] του [X/Y] , [X/Y] .\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'του', 'Brody', 'Raion', ',', 'Brody', '.'] ['Το', 'κεφάλαιο', 'του', 'Caddo', 'Parish', ',', 'το', 'Shreveport', '.']\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'του', 'Brody', 'Raion', ',', 'Brody', '.'] ['Το', 'κεφάλαιο', 'της', 'Νεμπράσκα', ',', 'το', 'Λίνκολν', '.']\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'του', 'Brody', 'Raion', ',', 'Brody', '.'] ['Το', 'κεφάλαιο', 'του', 'Hampshire', ',', 'το', 'Winchester', '.']\n",
      "searching lcs between: ['Cook', \"County's\", 'Capital', ',', 'Σικάγο', '.'] ['Το', 'κεφάλαιο', 'της', 'κομητείας', 'Fort', 'Bend', ',', 'Richmond', '.']\n",
      "searching lcs between: ['Cook', \"County's\", 'Capital', ',', 'Σικάγο', '.'] ['Το', 'κεφάλαιο', 'της', 'Cayuga', 'County', ',', 'Auburn', '.']\n",
      "searching lcs between: ['Cook', \"County's\", 'Capital', ',', 'Σικάγο', '.'] ['Πόλη', 'της', 'πρωτεύουσας', 'του', 'Hawkesbury', ',', 'Windsor', '.']\n",
      "searching lcs between: ['Cook', \"County's\", 'Capital', ',', 'Σικάγο', '.'] ['Κεφάλαιο', 'του', 'Grand', 'Est', ',', 'Στρασβούργο', '.']\n",
      "searching lcs between: ['Cook', \"County's\", 'Capital', ',', 'Σικάγο', '.'] ['Το', 'κεφάλαιο', 'του', 'Caddo', 'Parish', ',', 'το', 'Shreveport', '.']\n",
      "searching lcs between: ['Cook', \"County's\", 'Capital', ',', 'Σικάγο', '.'] ['Το', 'κεφάλαιο', 'της', 'Νεμπράσκα', ',', 'το', 'Λίνκολν', '.']\n",
      "searching lcs between: ['Cook', \"County's\", 'Capital', ',', 'Σικάγο', '.'] ['Το', 'κεφάλαιο', 'του', 'Hampshire', ',', 'το', 'Winchester', '.']\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'της', 'κομητείας', 'Fort', 'Bend', ',', 'Richmond', '.'] ['Το', 'κεφάλαιο', 'της', 'Cayuga', 'County', ',', 'Auburn', '.']\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'της', 'κομητείας', 'Fort', 'Bend', ',', 'Richmond', '.'] ['Πόλη', 'της', 'πρωτεύουσας', 'του', 'Hawkesbury', ',', 'Windsor', '.']\n",
      "Error in lcs, there aren't two '[X/Y]': [X/Y] της [X/Y] , [X/Y] .\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'της', 'κομητείας', 'Fort', 'Bend', ',', 'Richmond', '.'] ['Κεφάλαιο', 'του', 'Grand', 'Est', ',', 'Στρασβούργο', '.']\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'της', 'κομητείας', 'Fort', 'Bend', ',', 'Richmond', '.'] ['Το', 'κεφάλαιο', 'του', 'Caddo', 'Parish', ',', 'το', 'Shreveport', '.']\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'της', 'κομητείας', 'Fort', 'Bend', ',', 'Richmond', '.'] ['Το', 'κεφάλαιο', 'της', 'Νεμπράσκα', ',', 'το', 'Λίνκολν', '.']\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'της', 'κομητείας', 'Fort', 'Bend', ',', 'Richmond', '.'] ['Το', 'κεφάλαιο', 'του', 'Hampshire', ',', 'το', 'Winchester', '.']\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'της', 'Cayuga', 'County', ',', 'Auburn', '.'] ['Πόλη', 'της', 'πρωτεύουσας', 'του', 'Hawkesbury', ',', 'Windsor', '.']\n",
      "Error in lcs, there aren't two '[X/Y]': [X/Y] της [X/Y] , [X/Y] .\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'της', 'Cayuga', 'County', ',', 'Auburn', '.'] ['Κεφάλαιο', 'του', 'Grand', 'Est', ',', 'Στρασβούργο', '.']\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'της', 'Cayuga', 'County', ',', 'Auburn', '.'] ['Το', 'κεφάλαιο', 'του', 'Caddo', 'Parish', ',', 'το', 'Shreveport', '.']\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'της', 'Cayuga', 'County', ',', 'Auburn', '.'] ['Το', 'κεφάλαιο', 'της', 'Νεμπράσκα', ',', 'το', 'Λίνκολν', '.']\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'της', 'Cayuga', 'County', ',', 'Auburn', '.'] ['Το', 'κεφάλαιο', 'του', 'Hampshire', ',', 'το', 'Winchester', '.']\n",
      "searching lcs between: ['Πόλη', 'της', 'πρωτεύουσας', 'του', 'Hawkesbury', ',', 'Windsor', '.'] ['Κεφάλαιο', 'του', 'Grand', 'Est', ',', 'Στρασβούργο', '.']\n",
      "Error in lcs, there aren't two '[X/Y]': [X/Y] του [X/Y] , [X/Y] .\n",
      "searching lcs between: ['Πόλη', 'της', 'πρωτεύουσας', 'του', 'Hawkesbury', ',', 'Windsor', '.'] ['Το', 'κεφάλαιο', 'του', 'Caddo', 'Parish', ',', 'το', 'Shreveport', '.']\n",
      "Error in lcs, there aren't two '[X/Y]': [X/Y] του [X/Y] , [X/Y] .\n",
      "searching lcs between: ['Πόλη', 'της', 'πρωτεύουσας', 'του', 'Hawkesbury', ',', 'Windsor', '.'] ['Το', 'κεφάλαιο', 'της', 'Νεμπράσκα', ',', 'το', 'Λίνκολν', '.']\n",
      "Error in lcs, there aren't two '[X/Y]': [X/Y] της [X/Y] , [X/Y] .\n",
      "searching lcs between: ['Πόλη', 'της', 'πρωτεύουσας', 'του', 'Hawkesbury', ',', 'Windsor', '.'] ['Το', 'κεφάλαιο', 'του', 'Hampshire', ',', 'το', 'Winchester', '.']\n",
      "Error in lcs, there aren't two '[X/Y]': [X/Y] του [X/Y] , [X/Y] .\n",
      "searching lcs between: ['Κεφάλαιο', 'του', 'Grand', 'Est', ',', 'Στρασβούργο', '.'] ['Το', 'κεφάλαιο', 'του', 'Caddo', 'Parish', ',', 'το', 'Shreveport', '.']\n",
      "Error in lcs, there aren't two '[X/Y]': [X/Y] του [X/Y] , [X/Y] .\n",
      "searching lcs between: ['Κεφάλαιο', 'του', 'Grand', 'Est', ',', 'Στρασβούργο', '.'] ['Το', 'κεφάλαιο', 'της', 'Νεμπράσκα', ',', 'το', 'Λίνκολν', '.']\n",
      "searching lcs between: ['Κεφάλαιο', 'του', 'Grand', 'Est', ',', 'Στρασβούργο', '.'] ['Το', 'κεφάλαιο', 'του', 'Hampshire', ',', 'το', 'Winchester', '.']\n",
      "Error in lcs, there aren't two '[X/Y]': [X/Y] του [X/Y] , [X/Y] .\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'του', 'Caddo', 'Parish', ',', 'το', 'Shreveport', '.'] ['Το', 'κεφάλαιο', 'της', 'Νεμπράσκα', ',', 'το', 'Λίνκολν', '.']\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'του', 'Caddo', 'Parish', ',', 'το', 'Shreveport', '.'] ['Το', 'κεφάλαιο', 'του', 'Hampshire', ',', 'το', 'Winchester', '.']\n",
      "searching lcs between: ['Το', 'κεφάλαιο', 'της', 'Νεμπράσκα', ',', 'το', 'Λίνκολν', '.'] ['Το', 'κεφάλαιο', 'του', 'Hampshire', ',', 'το', 'Winchester', '.']\n",
      "potential_templates: defaultdict(<class 'int'>, {'Το κεφάλαιο του [X/Y] , [X/Y] .': 3, '[X/Y] , [X/Y] .': 12, 'Το κεφάλαιο [X/Y] , [X/Y] .': 9, 'Το κεφάλαιο του [X/Y] , το [X/Y] .': 3, 'Το κεφάλαιο [X/Y] , το [X/Y] .': 3, 'Το κεφάλαιο της [X/Y] , [X/Y] .': 3})\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Το κεφάλαιο του [X] , [Y] .',\n",
       " '[X] , [Y] .',\n",
       " 'Το κεφάλαιο [X] , [Y] .',\n",
       " 'Το κεφάλαιο του [X] , το [Y] .',\n",
       " 'Το κεφάλαιο [X] , το [Y] .',\n",
       " 'Το κεφάλαιο της [X] , [Y] .']"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "def set_cleaned_words(list, index=None):\n",
    "    output = set()\n",
    "    for string in list:\n",
    "        if index is not None:\n",
    "            string = string[index]\n",
    "        for word in string.split(' '):\n",
    "            word = re.sub('[.,:]', '', re.sub('[.,:]', '', word))\n",
    "            word = re.sub(' +', ' ', word)\n",
    "            output.add(word.lower())\n",
    "    return output\n",
    "\n",
    "def get_object_subject_order(set_first_position, set_second_position, en_tuples, translated_tuples):\n",
    "    set_first_position = set_cleaned_words(set_first_position)\n",
    "    set_second_position = set_cleaned_words(set_second_position)\n",
    "    subj_en = set_cleaned_words(en_tuples, 0)\n",
    "    obj_en = set_cleaned_words(en_tuples, 1)\n",
    "    subj_translated = set_cleaned_words(translated_tuples, 0)\n",
    "    obj_translated = set_cleaned_words(translated_tuples, 1)\n",
    "    total_subj = len(subj_en) + len(subj_translated)\n",
    "    total_obj = len(obj_en) + len(obj_translated)\n",
    "    first_subj = (len(set_first_position.intersection(subj_en)) + \n",
    "                  len(set_first_position.intersection(subj_translated)))/total_subj\n",
    "    first_obj = (len(set_first_position.intersection(obj_en)) + \n",
    "                 len(set_first_position.intersection(obj_translated)))/total_obj\n",
    "    second_subj = (len(set_second_position.intersection(subj_en)) + \n",
    "                   len(set_second_position.intersection(subj_translated)))/total_subj\n",
    "    second_obj = (len(set_second_position.intersection(obj_en)) + \n",
    "                  len(set_second_position.intersection(obj_translated)))/total_obj\n",
    "    if first_subj > second_subj and first_obj < second_obj:\n",
    "        return [\"[X]\", \"[Y]\"]\n",
    "    elif first_subj < second_subj and first_obj > second_obj:\n",
    "        return [\"[Y]\", \"[X]\"]\n",
    "    else:\n",
    "        print(\"Error: couldn't conclude on order of X and Y\")\n",
    "        print(\"first_subj={}, first_obj={}, second_subj={}, second_obj={}\".format(\n",
    "            first_subj, first_obj, second_subj, second_obj))\n",
    "        print(\"set_first_position:\", set_first_position)\n",
    "        print(\"set_second_position:\", set_second_position)\n",
    "        print(\"subj_en:\", subj_en)\n",
    "        print(\"subj_translated:\", subj_translated)\n",
    "        print(\"obj_en:\", obj_en)\n",
    "        print(\"obj_translated:\", obj_translated)\n",
    "        return None, None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "def get_words_list(sentence):\n",
    "    sentence = sentence.replace(',', ' , ')\n",
    "    sentence = sentence.replace('.', ' . ')\n",
    "    sentence = sentence.replace(':', ' : ')\n",
    "    sentence = re.sub(' +', ' ', sentence)\n",
    "    sentence = re.sub(' $', '', sentence)\n",
    "    return sentence.split(' ')\n",
    "\n",
    "\n",
    "def get_templates_from_populated_translations(translated_phrases: List, en_tuples: List, translated_tuples: List):\n",
    "    \"\"\"Returns the templates that are present in more than one translation.\n",
    "\n",
    "    The template is defined as the longest common subsequence of words between\n",
    "    more than two translations. It assumes that [X] and [Y] are positioned where\n",
    "    words are skipped (i.e. do not match) in both of the translations. For\n",
    "    defining which one is [X] and which one [Y] it simply compares the words\n",
    "    skipped with the tuples passed as arguments.\n",
    "\n",
    "    Args:\n",
    "        translated_phrases: list with the translated phrases.\n",
    "        en_tuples: List containing the tuples (subject, object) used to populate the templates. \n",
    "        en_tuples: List containing the tuples (subject, object) that are the translation of the tuples in english. \n",
    "    Returns:\n",
    "        List of templates where each contains exactly one [X] and one [Y].\n",
    "    \"\"\"\n",
    "    potential_templates = collections.defaultdict(int)\n",
    "    # Each set contains the phrases for the object/subject found.\n",
    "    non_overlapping_phrases = [set(), set()]\n",
    "    for i in range(0, len(translated_phrases)):\n",
    "        for j in range(i+1, len(translated_phrases)):\n",
    "            lcs, non_overlapping = longest_common_subsequence(\n",
    "                get_words_list(translated_phrases[i]),\n",
    "                get_words_list(translated_phrases[j]))\n",
    "            if not lcs:\n",
    "                continue\n",
    "            if lcs.count(\"[X/Y]\") != 2:\n",
    "                print(\"Error in lcs, there aren't two '[X/Y]':\", lcs)\n",
    "                continue\n",
    "            for subject_or_object in non_overlapping[0]:\n",
    "                non_overlapping_phrases[0].add(subject_or_object)\n",
    "            for subject_or_object in non_overlapping[1]:\n",
    "                non_overlapping_phrases[1].add(subject_or_object)\n",
    "            potential_templates[lcs] += 1\n",
    "    print(\"potential_templates:\", potential_templates)\n",
    "    first_str, second_str = get_object_subject_order(\n",
    "        *non_overlapping_phrases, en_tuples, translated_tuples)\n",
    "    if first_str is None:\n",
    "        return []\n",
    "    final_templates = []\n",
    "    for template, _ in filter(lambda x: x[1] > 1, potential_templates.items()):\n",
    "        final_tempalte = template.replace(\"[X/Y]\", first_str, 1)\n",
    "        final_templates.append(final_tempalte.replace(\"[X/Y]\", second_str, 1))\n",
    "    return final_templates"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "lang = \"el\"\n",
    "\n",
    "for template in templates[4:5]:\n",
    "    print(\">>>>>>> template:\", template[\"pattern\"])\n",
    "    en_tuples = get_k_subject_object_tuples(\n",
    "        os.path.join(tuples_folder, \"en\", \"triples\", relation_filename),\n",
    "        K_POPULATED_TEMPLATES)\n",
    "    print(\"en_tuples:\\n\", en_tuples.items())\n",
    "    translated_tuples = get_subject_object_tuples_from_lines(\n",
    "        os.path.join(tuples_folder, lang, \"triples\", relation_filename),\n",
    "        en_tuples.keys())\n",
    "    print(\"translated_tuples:\\n\", translated_tuples.items())\n",
    "    populated_phrases = get_populated_phrases(template['pattern'], en_tuples.values())\n",
    "    print(\"populated_phrases:\\n\", populated_phrases)\n",
    "    translated_phrases = [translator.translate(text, \"en\", lang)\n",
    "                          for text in populated_phrases]\n",
    "    print(\"translated_phrases:\\n\", translated_phrases)\n",
    "    final_templates = get_templates_from_populated_translations(\n",
    "        translated_phrases, en_tuples.values(), translated_tuples.values())\n",
    "    print(\"final_templates:\", final_templates)\n",
    "    print()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>>>>>> template: [X]'s capital, [Y].\n",
      "en_tuples:\n",
      " dict_items([(0, ('Azerbaijan', 'Baku')), (1, ('Brody Raion', 'Brody')), (2, ('Cook County', 'Chicago')), (3, ('Fort Bend County', 'Richmond')), (4, ('Cayuga County', 'Auburn')), (5, ('City of Hawkesbury', 'Windsor')), (6, ('Grand Est', 'Strasbourg')), (7, ('Caddo Parish', 'Shreveport')), (8, ('Nebraska', 'Lincoln')), (9, ('Hampshire', 'Winchester'))])\n",
      "translated_tuples:\n",
      " dict_items([(0, ('Αζερμπαϊτζάν', 'Μπακού')), (2, ('Κομητεία Κουκ', 'Σικάγο')), (6, ('Γκραντ Εστ', 'Στρασβούργο')), (8, ('Νεμπράσκα', 'Λίνκολν')), (9, ('Χάμπσαϊρ', 'Γουίντσεστερ'))])\n",
      "populated_phrases:\n",
      " [\"Azerbaijan's capital, Baku.\", \"Brody Raion's capital, Brody.\", \"Cook County's capital, Chicago.\", \"Fort Bend County's capital, Richmond.\", \"Cayuga County's capital, Auburn.\", \"City of Hawkesbury's capital, Windsor.\", \"Grand Est's capital, Strasbourg.\", \"Caddo Parish's capital, Shreveport.\", \"Nebraska's capital, Lincoln.\", \"Hampshire's capital, Winchester.\"]\n",
      "translated_phrases:\n",
      " ['Το κεφάλαιο του Αζερμπαϊτζάν, το Μπακού.', 'Το κεφάλαιο του Brody Raion, Brody.', \"Cook County's Capital, Σικάγο.\", 'Το κεφάλαιο της κομητείας Fort Bend, Richmond.', 'Το κεφάλαιο της Cayuga County, Auburn.', 'Πόλη της πρωτεύουσας του Hawkesbury, Windsor.', 'Κεφάλαιο του Grand Est, Στρασβούργο.', 'Το κεφάλαιο του Caddo Parish, το Shreveport.', 'Το κεφάλαιο της Νεμπράσκα, το Λίνκολν.', 'Το κεφάλαιο του Hampshire, το Winchester.']\n",
      "Error in lcs, there aren't two '[X/Y]': Το κεφάλαιο του [X/Y]\n",
      "Error in lcs, there aren't two '[X/Y]': Το κεφάλαιο [X/Y]\n",
      "Error in lcs, there aren't two '[X/Y]': Το κεφάλαιο [X/Y]\n",
      "Error in lcs, there aren't two '[X/Y]': Το κεφάλαιο [X/Y]\n",
      "Error in lcs, there aren't two '[X/Y]': Το κεφάλαιο [X/Y]\n",
      "Error in lcs, there aren't two '[X/Y]': Το κεφάλαιο του [X/Y]\n",
      "Error in lcs, there aren't two '[X/Y]': Το κεφάλαιο [X/Y]\n",
      "Error in lcs, there aren't two '[X/Y]': Το κεφάλαιο του [X/Y]\n",
      "Error in lcs, there aren't two '[X/Y]': Το κεφάλαιο της [X/Y]\n",
      "Error in lcs, there aren't two '[X/Y]': Το κεφάλαιο [X/Y]\n",
      "Error in lcs, there aren't two '[X/Y]': Το κεφάλαιο της [X/Y]\n",
      "Error in lcs, there aren't two '[X/Y]': Το κεφάλαιο [X/Y]\n",
      "Error in lcs, there aren't two '[X/Y]': Το κεφάλαιο [X/Y]\n",
      "Error in lcs, there aren't two '[X/Y]': Το κεφάλαιο της [X/Y]\n",
      "Error in lcs, there aren't two '[X/Y]': Το κεφάλαιο [X/Y]\n",
      "potential_templates: defaultdict(<class 'int'>, {'[X/Y] του [X/Y]': 9, 'Το κεφάλαιο του [X/Y] το [X/Y]': 3, 'Το κεφάλαιο [X/Y] το [X/Y]': 3, '[X/Y] της [X/Y]': 3})\n",
      "Error: couldn't conclude on order of X and Y\n",
      "first_subj=0.20833333333333334, first_obj=0.0, second_subj=0.5833333333333334, second_obj=0.6\n",
      "set_first_position: {'parish', 'το', 'κεφάλαιο', 'hampshire', 'πόλη', 'νεμπράσκα', 'της', 'του', 'caddo', 'πρωτεύουσας', 'αζερμπαϊτζάν'}\n",
      "set_second_position: {'στρασβούργο', 'hampshire', 'λίνκολν', 'auburn', 'πρωτεύουσας', 'hawkesbury', 'μπακού', 'shreveport', 'grand', 'το', 'county', 'cayuga', 'κομητείας', 'brody', 'winchester', 'est', 'του', 'νεμπράσκα', 'caddo', 'windsor', 'αζερμπαϊτζάν', 'parish', 'bend', 'richmond', 'fort', 'raion'}\n",
      "subj_en: {'parish', 'nebraska', 'grand', 'county', 'bend', 'cayuga', 'brody', 'cook', 'caddo', 'fort', 'hampshire', 'est', 'raion', 'city', 'of', 'hawkesbury', 'azerbaijan'}\n",
      "subj_translated: {'εστ', 'κουκ', 'χάμπσαϊρ', 'γκραντ', 'κομητεία', 'νεμπράσκα', 'αζερμπαϊτζάν'}\n",
      "obj_en: {'shreveport', 'baku', 'strasbourg', 'brody', 'lincoln', 'richmond', 'chicago', 'winchester', 'auburn', 'windsor'}\n",
      "obj_translated: {'γουίντσεστερ', 'στρασβούργο', 'λίνκολν', 'σικάγο', 'μπακού'}\n",
      "final_templates: []\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit ('mpararel-venv': venv)"
  },
  "interpreter": {
   "hash": "7b00635ec3dadc89d55ed82a60ecbee89d88a1e660533522094ac0dd7657354a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}